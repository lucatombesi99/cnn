{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNRU3mp04WULfTpF00a/IM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucatombesi99/cnn/blob/main/cnn_build.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc6lmNuT50KI",
        "outputId": "0a341d68-74c9-46c0-f318-29d68f679a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/ANN_Challenge2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S58g_RU56rL",
        "outputId": "0e7b03a6-f905-4437-a758-da5e96f2c975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ANN_Challenge2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "import logging\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o7DlFzP58hJ",
        "outputId": "1a1f0b53-e9b1-4066-f973-42a9b7801067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load('/content/drive/My Drive/ANN_Challenge2/training_dataset_homework2/x_train.npy')\n",
        "y_train = np.load('/content/drive/My Drive/ANN_Challenge2/training_dataset_homework2/y_train.npy')"
      ],
      "metadata": {
        "id": "E9WrNj5i5-tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute mean and std per feature\n",
        "data_mean = np.empty(shape=6)\n",
        "data_std = np.empty(shape=6)\n",
        "data_max = np.empty(shape=6)\n",
        "data_min = np.empty(shape=6)\n",
        "data_median = np.empty(shape=6)\n",
        "\n",
        "for i in range(6):\n",
        "  data_mean[i] = X_train[:,:,i].mean()\n",
        "  data_std[i] = X_train[:,:,i].std()\n",
        "  data_min[i] = X_train[:,:,i].min()\n",
        "  data_max[i] = X_train[:,:,i].max()\n",
        "  data_median[i] = np.median(X_train[:,:,i])"
      ],
      "metadata": {
        "id": "yy1M9uzCNCm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_min = np.empty(shape=6)\n",
        "data_max = np.empty(shape=6)\n",
        "\n",
        "for i in range(6):\n",
        "  data_min[i] = X_train[:,:,i].min()\n",
        "  data_max[i] = X_train[:,:,i].max()\n",
        "\n",
        "x = np.reshape(X_train,(X_train.shape[0]*X_train.shape[1], 6))\n",
        "x = (x - data_min)/(data_max-data_min)\n",
        "x = pd.DataFrame(x)\n",
        "x.boxplot(figsize=(8,24))"
      ],
      "metadata": {
        "id": "02VBpYM46B84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1305e04f-7473-4cc8-9d14-0879b9100215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f689cb375b0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x1728 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.argmax(y_train, axis=1)\n",
        "\n",
        "for i in range(12):\n",
        "  print(i,\"\\t\",len(y[y ==i]))"
      ],
      "metadata": {
        "id": "19e4ehli6F47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "402a71bc-bfed-42a6-80ea-ce84f6e17b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-adfb7c555de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \"\"\"\n\u001b[0;32m-> 1195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMAsLcm76NsN",
        "outputId": "19f8c34c-e83f-4023-8baa-d2dcd7310d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2429, 36, 6), (2429,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureSelectionLayer(tfkl.Layer):\n",
        "  def __init__(self, features):\n",
        "    super(FeatureSelectionLayer, self).__init__()\n",
        "    self.features = features\n",
        "  def call(self, inputs):\n",
        "    return tf.gather(inputs, indices=self.features, axis = 2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6PdgpcoYDXnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1RAwfe56PoL",
        "outputId": "2dcdb70e-5cb8-4561-d9e4-f0be6632be14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, classes, mean, std, features):\n",
        "    input_layer = tfkl.Input(input_shape)\n",
        "\n",
        "    scaler = CustomScalerLayer(mean,std)(input_layer)\n",
        "\n",
        "    feature_selector = FeatureSelectionLayer(features)(scaler)\n",
        "\n",
        "    # BLOCK 1\n",
        "    conv1 = tfkl.Conv1D(64, 8, padding='same')(feature_selector)\n",
        "    conv1 = tfkl.Activation('relu')(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv1D(64, 5, padding='same')(conv1)\n",
        "    conv2 = tfkl.Activation('relu')(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv1D(64, 3, padding='same')(conv2)\n",
        "\n",
        "    # expand channels for the sum\n",
        "\n",
        "    shortcut = tfkl.Conv1D(filters=64, kernel_size=1, padding='same')(feature_selector)\n",
        "    shortcut = tfkl.BatchNormalization()(shortcut)\n",
        "\n",
        "    output_layer_block_1 = tfkl.add([shortcut, conv3])\n",
        "    output_layer_block_1 = tfkl.Activation('relu')(output_layer_block_1)\n",
        "\n",
        "    # BLOCK 2\n",
        "    conv1 = tfkl.Conv1D(128, 8, padding='same')(output_layer_block_1)\n",
        "    conv1 = tfkl.Activation('relu')(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv1D(128, 5, padding='same')(conv1)\n",
        "    conv2 = tfkl.Activation('relu')(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv1D(128, 3, padding='same')(conv2)\n",
        "\n",
        "    # expand channels for the sum\n",
        "\n",
        "    shortcut = tfkl.Conv1D(filters=128, kernel_size=1, padding='same')(output_layer_block_1)\n",
        "    shortcut = tfkl.BatchNormalization()(shortcut)\n",
        "\n",
        "    output_layer_block_2 = tfkl.add([shortcut, conv3])\n",
        "    output_layer_block_2 = tfkl.Activation('relu')(output_layer_block_2)\n",
        "\n",
        "    # BLOCK 3\n",
        "    #conv1 = tfkl.Conv1D(128, 8, padding='same')(output_layer_block_2)\n",
        "    #conv1 = tfkl.Activation('relu')(conv1)\n",
        "\n",
        "    #conv2 = tfkl.Conv1D(128, 5, padding='same')(conv1)\n",
        "    #conv2 = tfkl.Activation('relu')(conv2)\n",
        "\n",
        "    #conv3 = tfkl.Conv1D(128, 3, padding='same')(conv2)\n",
        "\n",
        "    # no need to expand channels because they are equal\n",
        "    #shortcut = tfkl.BatchNormalization()(output_layer_block_2)\n",
        "\n",
        "    #output_layer_block_3 = tfkl.add([shortcut, conv3])\n",
        "    #output_layer_block_3 = tfkl.Activation('relu')(output_layer_block_3)\n",
        "\n",
        "    # FINAL\n",
        "    #attention = tfkl.MultiHeadAttention(10,32)(output_layer_block_3, output_layer_block_3)\n",
        "\n",
        "    #gap_layer = tfkl.GlobalAveragePooling1D()(output_layer_block_3)\n",
        "\n",
        "    lstm = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True))(output_layer_block_2)\n",
        "    lstm = tfkl.Dropout(0.5)(lstm)\n",
        "    lstm = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True))(lstm)\n",
        "    lstm = tfkl.Dropout(0.5)(lstm)\n",
        "\n",
        "    attention = tfkl.MultiHeadAttention(10,32)(lstm, lstm)\n",
        "\n",
        "    gap_layer = tfkl.GlobalAveragePooling1D()(attention)\n",
        "    classifier = tfkl.Dense(128)(gap_layer)\n",
        "    classifier = tfkl.Dropout(0.5)(classifier)\n",
        "\n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "OKK8B8-x6Rng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIpr6I2KMpSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = 12\n",
        "batch_size = 64\n",
        "epochs = 200"
      ],
      "metadata": {
        "id": "QN5kinKdMlqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomScalerLayer(tfkl.Layer):\n",
        "  def __init__(self, mean, std):\n",
        "    super(CustomScalerLayer, self).__init__()\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "  def call(self, inputs):\n",
        "    return (inputs - self.mean)/self.std"
      ],
      "metadata": {
        "id": "yuYdlLt6MmXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the sparse labels to categorical values\n",
        "y_train = tfk.utils.to_categorical(y_train)\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRhxKxhckSUG",
        "outputId": "e36429e5-0573-43f5-9625-8e3e0828133a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2429, 36, 6), (2429, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
      ],
      "metadata": {
        "id": "IFkPcWEz9JKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid= X_train[2000:,:,:]\n",
        "Y_valid= y_train[2000:,:]\n",
        "X_train=X_train[:2000,:,:]\n",
        "y_train=y_train[:2000,:]"
      ],
      "metadata": {
        "id": "SfdQS-wUOXfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute mean and std per feature\n",
        "data_mean = np.empty(shape=6)\n",
        "data_std = np.empty(shape=6)\n",
        "data_max = np.empty(shape=6)\n",
        "data_min = np.empty(shape=6)\n",
        "data_median = np.empty(shape=6)\n",
        "data_iqr = np.empty(shape=6)\n",
        "\n",
        "for i in range(6):\n",
        "  data_mean[i] = X_train[:,:,i].mean()\n",
        "  data_std[i] = X_train[:,:,i].std()\n",
        "  data_min[i] = X_train[:,:,i].min()\n",
        "  data_max[i] = X_train[:,:,i].max()\n",
        "  data_median[i] = np.median(X_train[:,:,i])\n",
        "  data_iqr[i] = np.subtract(*np.percentile(X_train[:,:,i], [75, 25]))"
      ],
      "metadata": {
        "id": "kTDV33ie9CAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(input_shape, classes, data_mean, (data_max-data_min),[0,1,2,3,4,5])\n",
        "history = model.fit(\n",
        "      x = X_train,\n",
        "      y = y_train,\n",
        "      batch_size = batch_size,\n",
        "      epochs = epochs,\n",
        "      validation_split=.2,\n",
        "      callbacks = [\n",
        "          tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=50, restore_best_weights=True),\n",
        "          tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.5, min_lr=1e-5),\n",
        "\n",
        "      ]\n",
        ").history\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sij5ZoJ55L3d",
        "outputId": "c6afa55b-5dcb-4899-a555-38d2ea9c0be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "31/31 [==============================] - 18s 89ms/step - loss: 2.0627 - accuracy: 0.3392 - val_loss: 2.2068 - val_accuracy: 0.3477 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 1.8797 - accuracy: 0.3824 - val_loss: 2.1399 - val_accuracy: 0.3477 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 1.7786 - accuracy: 0.4189 - val_loss: 2.1847 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 1.7277 - accuracy: 0.4061 - val_loss: 2.0695 - val_accuracy: 0.3519 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.6200 - accuracy: 0.4653 - val_loss: 2.1056 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 1.5455 - accuracy: 0.4817 - val_loss: 2.1324 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 1.4869 - accuracy: 0.4905 - val_loss: 2.2760 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 1.4419 - accuracy: 0.5147 - val_loss: 2.1690 - val_accuracy: 0.3498 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.4020 - accuracy: 0.5183 - val_loss: 2.5796 - val_accuracy: 0.3539 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 1.3405 - accuracy: 0.5425 - val_loss: 4.9103 - val_accuracy: 0.0988 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.2623 - accuracy: 0.5646 - val_loss: 4.3983 - val_accuracy: 0.0988 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 1s 29ms/step - loss: 1.2203 - accuracy: 0.5744 - val_loss: 7.5588 - val_accuracy: 0.1008 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 1s 31ms/step - loss: 1.2124 - accuracy: 0.5852 - val_loss: 2.8817 - val_accuracy: 0.3642 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 1s 27ms/step - loss: 1.1826 - accuracy: 0.5980 - val_loss: 3.7147 - val_accuracy: 0.1399 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 1s 26ms/step - loss: 1.1763 - accuracy: 0.5975 - val_loss: 4.4930 - val_accuracy: 0.1420 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.1438 - accuracy: 0.6140 - val_loss: 8.0530 - val_accuracy: 0.0926 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.1127 - accuracy: 0.6104 - val_loss: 9.5338 - val_accuracy: 0.1008 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 1.2805 - accuracy: 0.5878 - val_loss: 8.5906 - val_accuracy: 0.1173 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.1048 - accuracy: 0.6284 - val_loss: 11.0496 - val_accuracy: 0.1111 - lr: 5.0000e-04\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 1.0169 - accuracy: 0.6526 - val_loss: 8.4259 - val_accuracy: 0.1235 - lr: 5.0000e-04\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.9920 - accuracy: 0.6742 - val_loss: 10.8470 - val_accuracy: 0.0350 - lr: 5.0000e-04\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.9565 - accuracy: 0.6809 - val_loss: 11.4087 - val_accuracy: 0.0370 - lr: 5.0000e-04\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.9746 - accuracy: 0.6727 - val_loss: 10.3084 - val_accuracy: 0.0412 - lr: 5.0000e-04\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.9121 - accuracy: 0.6907 - val_loss: 10.8974 - val_accuracy: 0.0412 - lr: 2.5000e-04\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.9069 - accuracy: 0.7036 - val_loss: 8.4667 - val_accuracy: 0.1296 - lr: 2.5000e-04\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.8873 - accuracy: 0.6994 - val_loss: 8.3917 - val_accuracy: 0.1317 - lr: 2.5000e-04\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.8707 - accuracy: 0.7128 - val_loss: 5.8699 - val_accuracy: 0.0782 - lr: 2.5000e-04\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.8770 - accuracy: 0.7036 - val_loss: 10.9512 - val_accuracy: 0.1091 - lr: 2.5000e-04\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.8344 - accuracy: 0.7174 - val_loss: 10.0194 - val_accuracy: 0.0658 - lr: 1.2500e-04\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.8360 - accuracy: 0.7159 - val_loss: 10.3859 - val_accuracy: 0.0864 - lr: 1.2500e-04\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.8119 - accuracy: 0.7247 - val_loss: 10.7329 - val_accuracy: 0.1276 - lr: 1.2500e-04\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.8125 - accuracy: 0.7231 - val_loss: 12.0013 - val_accuracy: 0.1337 - lr: 1.2500e-04\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.8132 - accuracy: 0.7303 - val_loss: 13.8155 - val_accuracy: 0.1440 - lr: 1.2500e-04\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.8015 - accuracy: 0.7288 - val_loss: 12.8322 - val_accuracy: 0.1461 - lr: 6.2500e-05\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7969 - accuracy: 0.7370 - val_loss: 12.2160 - val_accuracy: 0.1440 - lr: 6.2500e-05\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7847 - accuracy: 0.7396 - val_loss: 7.7194 - val_accuracy: 0.1955 - lr: 6.2500e-05\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7744 - accuracy: 0.7458 - val_loss: 4.0805 - val_accuracy: 0.3374 - lr: 6.2500e-05\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7821 - accuracy: 0.7349 - val_loss: 4.7077 - val_accuracy: 0.3436 - lr: 6.2500e-05\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7577 - accuracy: 0.7447 - val_loss: 4.3107 - val_accuracy: 0.3436 - lr: 3.1250e-05\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7685 - accuracy: 0.7401 - val_loss: 3.5617 - val_accuracy: 0.4218 - lr: 3.1250e-05\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7993 - accuracy: 0.7380 - val_loss: 3.5956 - val_accuracy: 0.4095 - lr: 3.1250e-05\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7851 - accuracy: 0.7298 - val_loss: 5.9859 - val_accuracy: 0.2551 - lr: 3.1250e-05\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7635 - accuracy: 0.7406 - val_loss: 3.8318 - val_accuracy: 0.3704 - lr: 3.1250e-05\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7725 - accuracy: 0.7380 - val_loss: 2.1630 - val_accuracy: 0.5000 - lr: 3.1250e-05\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7703 - accuracy: 0.7329 - val_loss: 3.3155 - val_accuracy: 0.4486 - lr: 3.1250e-05\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7874 - accuracy: 0.7370 - val_loss: 5.1800 - val_accuracy: 0.3272 - lr: 3.1250e-05\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7661 - accuracy: 0.7447 - val_loss: 2.4039 - val_accuracy: 0.4897 - lr: 3.1250e-05\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7728 - accuracy: 0.7375 - val_loss: 3.4235 - val_accuracy: 0.3663 - lr: 3.1250e-05\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7759 - accuracy: 0.7365 - val_loss: 2.7689 - val_accuracy: 0.4444 - lr: 3.1250e-05\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7667 - accuracy: 0.7406 - val_loss: 1.8705 - val_accuracy: 0.5391 - lr: 1.5625e-05\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7481 - accuracy: 0.7422 - val_loss: 1.5418 - val_accuracy: 0.5905 - lr: 1.5625e-05\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7565 - accuracy: 0.7411 - val_loss: 1.2644 - val_accuracy: 0.6193 - lr: 1.5625e-05\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7723 - accuracy: 0.7432 - val_loss: 1.1070 - val_accuracy: 0.6461 - lr: 1.5625e-05\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7604 - accuracy: 0.7427 - val_loss: 1.0236 - val_accuracy: 0.6708 - lr: 1.5625e-05\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7573 - accuracy: 0.7401 - val_loss: 1.0098 - val_accuracy: 0.6728 - lr: 1.5625e-05\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7638 - accuracy: 0.7437 - val_loss: 1.1156 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7557 - accuracy: 0.7473 - val_loss: 1.4951 - val_accuracy: 0.5535 - lr: 1.5625e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7567 - accuracy: 0.7494 - val_loss: 1.3996 - val_accuracy: 0.5700 - lr: 1.5625e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7537 - accuracy: 0.7458 - val_loss: 1.1983 - val_accuracy: 0.6420 - lr: 1.5625e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7457 - accuracy: 0.7519 - val_loss: 1.1171 - val_accuracy: 0.6440 - lr: 1.5625e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7382 - accuracy: 0.7519 - val_loss: 1.0358 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7596 - accuracy: 0.7411 - val_loss: 1.0118 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7398 - accuracy: 0.7478 - val_loss: 1.0127 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7497 - accuracy: 0.7545 - val_loss: 0.9949 - val_accuracy: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7601 - accuracy: 0.7422 - val_loss: 0.9750 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7579 - accuracy: 0.7468 - val_loss: 0.9801 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7434 - accuracy: 0.7447 - val_loss: 0.9780 - val_accuracy: 0.6708 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7585 - accuracy: 0.7313 - val_loss: 0.9619 - val_accuracy: 0.6852 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7477 - accuracy: 0.7535 - val_loss: 0.9772 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7507 - accuracy: 0.7365 - val_loss: 1.0025 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7394 - accuracy: 0.7524 - val_loss: 0.9984 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7326 - accuracy: 0.7463 - val_loss: 1.0131 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7431 - accuracy: 0.7427 - val_loss: 1.0225 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7445 - accuracy: 0.7509 - val_loss: 0.9979 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7435 - accuracy: 0.7514 - val_loss: 0.9921 - val_accuracy: 0.6831 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7281 - accuracy: 0.7499 - val_loss: 0.9857 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7474 - accuracy: 0.7504 - val_loss: 0.9737 - val_accuracy: 0.6934 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7587 - accuracy: 0.7478 - val_loss: 0.9662 - val_accuracy: 0.6934 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7491 - accuracy: 0.7483 - val_loss: 0.9643 - val_accuracy: 0.6914 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7447 - accuracy: 0.7452 - val_loss: 0.9545 - val_accuracy: 0.6914 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7548 - accuracy: 0.7514 - val_loss: 0.9553 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7435 - accuracy: 0.7468 - val_loss: 0.9691 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7277 - accuracy: 0.7535 - val_loss: 0.9681 - val_accuracy: 0.6872 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7394 - accuracy: 0.7524 - val_loss: 0.9641 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7303 - accuracy: 0.7597 - val_loss: 0.9656 - val_accuracy: 0.6852 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7340 - accuracy: 0.7555 - val_loss: 0.9684 - val_accuracy: 0.6872 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7484 - accuracy: 0.7514 - val_loss: 0.9855 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7524 - accuracy: 0.7427 - val_loss: 0.9826 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7380 - accuracy: 0.7566 - val_loss: 1.0152 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7453 - accuracy: 0.7468 - val_loss: 1.0194 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7238 - accuracy: 0.7576 - val_loss: 0.9811 - val_accuracy: 0.6811 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7444 - accuracy: 0.7483 - val_loss: 0.9788 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7213 - accuracy: 0.7602 - val_loss: 0.9691 - val_accuracy: 0.6728 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7760 - accuracy: 0.7432 - val_loss: 0.9610 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7428 - accuracy: 0.7437 - val_loss: 0.9753 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7348 - accuracy: 0.7463 - val_loss: 0.9665 - val_accuracy: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7432 - accuracy: 0.7458 - val_loss: 0.9643 - val_accuracy: 0.6934 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7539 - accuracy: 0.7432 - val_loss: 0.9705 - val_accuracy: 0.6934 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7388 - accuracy: 0.7504 - val_loss: 0.9578 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7286 - accuracy: 0.7519 - val_loss: 0.9575 - val_accuracy: 0.6872 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7181 - accuracy: 0.7571 - val_loss: 0.9541 - val_accuracy: 0.6852 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7311 - accuracy: 0.7566 - val_loss: 0.9741 - val_accuracy: 0.6811 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7172 - accuracy: 0.7617 - val_loss: 1.0045 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7400 - accuracy: 0.7509 - val_loss: 0.9784 - val_accuracy: 0.6708 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7328 - accuracy: 0.7452 - val_loss: 0.9787 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7427 - accuracy: 0.7509 - val_loss: 0.9908 - val_accuracy: 0.6728 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7207 - accuracy: 0.7519 - val_loss: 0.9951 - val_accuracy: 0.6852 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7253 - accuracy: 0.7622 - val_loss: 0.9826 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7382 - accuracy: 0.7540 - val_loss: 0.9901 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7296 - accuracy: 0.7540 - val_loss: 0.9983 - val_accuracy: 0.6811 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7252 - accuracy: 0.7576 - val_loss: 0.9904 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7270 - accuracy: 0.7612 - val_loss: 0.9826 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7310 - accuracy: 0.7597 - val_loss: 0.9905 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7377 - accuracy: 0.7427 - val_loss: 0.9953 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.7177 - accuracy: 0.7658 - val_loss: 0.9943 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7242 - accuracy: 0.7555 - val_loss: 0.9887 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7575 - accuracy: 0.7483 - val_loss: 0.9887 - val_accuracy: 0.6708 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7273 - accuracy: 0.7514 - val_loss: 0.9773 - val_accuracy: 0.6811 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7281 - accuracy: 0.7597 - val_loss: 0.9895 - val_accuracy: 0.6790 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7431 - accuracy: 0.7422 - val_loss: 1.0046 - val_accuracy: 0.6770 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "31/31 [==============================] - 1s 23ms/step - loss: 0.7440 - accuracy: 0.7396 - val_loss: 1.0040 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7273 - accuracy: 0.7545 - val_loss: 1.0121 - val_accuracy: 0.6728 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7306 - accuracy: 0.7571 - val_loss: 0.9855 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7286 - accuracy: 0.7597 - val_loss: 0.9974 - val_accuracy: 0.6728 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7210 - accuracy: 0.7519 - val_loss: 0.9984 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "31/31 [==============================] - 1s 22ms/step - loss: 0.7419 - accuracy: 0.7509 - val_loss: 0.9841 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "31/31 [==============================] - 1s 21ms/step - loss: 0.7203 - accuracy: 0.7524 - val_loss: 0.9844 - val_accuracy: 0.6728 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from itertools import combinations\n",
        "array=[0,1,2,3,4,5]\n",
        "list_combinations = list(combinations(array, 5))\n",
        "results = {}\n",
        "\n",
        "for i in range(len(list_combinations)):\n",
        "\n",
        "  filename='log'+str(i)+'.csv'\n",
        "  history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)\n",
        "  model = build_model(input_shape, classes, data_mean, (data_max-data_min),list_combinations[i])\n",
        "  history = model.fit(\n",
        "      x = X_train,\n",
        "      y = y_train,\n",
        "      batch_size = batch_size,\n",
        "      epochs = epochs,\n",
        "      validation_split=.2,\n",
        "      callbacks = [\n",
        "          tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=50, restore_best_weights=True),\n",
        "          tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.5, min_lr=1e-5),\n",
        "          history_logger\n",
        "      ]\n",
        "  ).history\n",
        "  max = np.argmax(history['val_accuracy'])\n",
        "  results[str(i)] = {'train_accuracy': history['accuracy'][max],'val_accuracy': history['val_accuracy'][max]}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMoN70y96XE0",
        "outputId": "112e3fc4-97dd-43ad-be06-1e1a9d7b6107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "31/31 [==============================] - 2s 27ms/step - loss: 2.0646 - accuracy: 0.3572 - val_loss: 2.2407 - val_accuracy: 0.3765 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.7855 - accuracy: 0.4195 - val_loss: 1.9609 - val_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.6413 - accuracy: 0.4611 - val_loss: 1.9683 - val_accuracy: 0.4321 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.4663 - accuracy: 0.5064 - val_loss: 1.8019 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.3565 - accuracy: 0.5311 - val_loss: 1.7506 - val_accuracy: 0.4383 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.3270 - accuracy: 0.5409 - val_loss: 1.7127 - val_accuracy: 0.4342 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2738 - accuracy: 0.5646 - val_loss: 1.6051 - val_accuracy: 0.4650 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.2477 - accuracy: 0.5553 - val_loss: 1.6367 - val_accuracy: 0.4486 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.1674 - accuracy: 0.5950 - val_loss: 1.6576 - val_accuracy: 0.4424 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0939 - accuracy: 0.6227 - val_loss: 1.8157 - val_accuracy: 0.4362 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.1211 - accuracy: 0.6161 - val_loss: 1.5022 - val_accuracy: 0.4856 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.1582 - accuracy: 0.6047 - val_loss: 1.3946 - val_accuracy: 0.5226 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0604 - accuracy: 0.6336 - val_loss: 1.7628 - val_accuracy: 0.4733 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0447 - accuracy: 0.6408 - val_loss: 1.3388 - val_accuracy: 0.5535 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0057 - accuracy: 0.6547 - val_loss: 1.4796 - val_accuracy: 0.5514 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0364 - accuracy: 0.6402 - val_loss: 1.3166 - val_accuracy: 0.5597 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9604 - accuracy: 0.6758 - val_loss: 1.3484 - val_accuracy: 0.5617 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.9541 - accuracy: 0.6686 - val_loss: 1.6247 - val_accuracy: 0.5514 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9464 - accuracy: 0.6835 - val_loss: 1.3232 - val_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9590 - accuracy: 0.6531 - val_loss: 1.2000 - val_accuracy: 0.6029 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.9087 - accuracy: 0.6927 - val_loss: 1.1979 - val_accuracy: 0.5885 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.8782 - accuracy: 0.7072 - val_loss: 1.3941 - val_accuracy: 0.5885 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9221 - accuracy: 0.6866 - val_loss: 1.6336 - val_accuracy: 0.5679 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9244 - accuracy: 0.6799 - val_loss: 1.2269 - val_accuracy: 0.5988 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8921 - accuracy: 0.6969 - val_loss: 1.3503 - val_accuracy: 0.5844 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8177 - accuracy: 0.7133 - val_loss: 1.0822 - val_accuracy: 0.6379 - lr: 5.0000e-04\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.7606 - accuracy: 0.7324 - val_loss: 1.1535 - val_accuracy: 0.6296 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.7416 - accuracy: 0.7380 - val_loss: 1.0661 - val_accuracy: 0.6461 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.7211 - accuracy: 0.7478 - val_loss: 1.0837 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.7663 - val_loss: 1.1188 - val_accuracy: 0.6379 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.7622 - val_loss: 1.1203 - val_accuracy: 0.6440 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6526 - accuracy: 0.7699 - val_loss: 1.0764 - val_accuracy: 0.6708 - lr: 5.0000e-04\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6529 - accuracy: 0.7777 - val_loss: 1.1560 - val_accuracy: 0.6379 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6410 - accuracy: 0.7761 - val_loss: 1.1481 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5992 - accuracy: 0.7977 - val_loss: 1.1051 - val_accuracy: 0.6790 - lr: 5.0000e-04\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6194 - accuracy: 0.7828 - val_loss: 1.3476 - val_accuracy: 0.5720 - lr: 5.0000e-04\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6271 - accuracy: 0.7838 - val_loss: 1.1643 - val_accuracy: 0.6605 - lr: 5.0000e-04\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5826 - accuracy: 0.7936 - val_loss: 1.2149 - val_accuracy: 0.6132 - lr: 5.0000e-04\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5863 - accuracy: 0.7972 - val_loss: 1.2970 - val_accuracy: 0.6296 - lr: 5.0000e-04\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5529 - accuracy: 0.8055 - val_loss: 1.3141 - val_accuracy: 0.6379 - lr: 5.0000e-04\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5521 - accuracy: 0.8065 - val_loss: 1.1764 - val_accuracy: 0.6626 - lr: 2.5000e-04\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5055 - accuracy: 0.8209 - val_loss: 1.1901 - val_accuracy: 0.6749 - lr: 2.5000e-04\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4968 - accuracy: 0.8281 - val_loss: 1.1673 - val_accuracy: 0.6626 - lr: 2.5000e-04\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4886 - accuracy: 0.8266 - val_loss: 1.2008 - val_accuracy: 0.6646 - lr: 2.5000e-04\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4909 - accuracy: 0.8312 - val_loss: 1.2108 - val_accuracy: 0.6523 - lr: 2.5000e-04\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4672 - accuracy: 0.8379 - val_loss: 1.2490 - val_accuracy: 0.6605 - lr: 1.2500e-04\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4367 - accuracy: 0.8492 - val_loss: 1.1780 - val_accuracy: 0.6667 - lr: 1.2500e-04\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4351 - accuracy: 0.8461 - val_loss: 1.2284 - val_accuracy: 0.6687 - lr: 1.2500e-04\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4610 - accuracy: 0.8451 - val_loss: 1.2609 - val_accuracy: 0.6626 - lr: 1.2500e-04\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4451 - accuracy: 0.8466 - val_loss: 1.2065 - val_accuracy: 0.6728 - lr: 1.2500e-04\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4354 - accuracy: 0.8513 - val_loss: 1.2315 - val_accuracy: 0.6667 - lr: 6.2500e-05\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.8513 - val_loss: 1.2208 - val_accuracy: 0.6646 - lr: 6.2500e-05\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4231 - accuracy: 0.8549 - val_loss: 1.2625 - val_accuracy: 0.6584 - lr: 6.2500e-05\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4308 - accuracy: 0.8574 - val_loss: 1.2429 - val_accuracy: 0.6543 - lr: 6.2500e-05\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4392 - accuracy: 0.8451 - val_loss: 1.2732 - val_accuracy: 0.6584 - lr: 6.2500e-05\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4083 - accuracy: 0.8626 - val_loss: 1.2524 - val_accuracy: 0.6605 - lr: 3.1250e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4344 - accuracy: 0.8549 - val_loss: 1.2671 - val_accuracy: 0.6584 - lr: 3.1250e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4160 - accuracy: 0.8554 - val_loss: 1.2318 - val_accuracy: 0.6584 - lr: 3.1250e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3948 - accuracy: 0.8652 - val_loss: 1.2226 - val_accuracy: 0.6687 - lr: 3.1250e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4286 - accuracy: 0.8580 - val_loss: 1.2377 - val_accuracy: 0.6626 - lr: 3.1250e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.8621 - val_loss: 1.2374 - val_accuracy: 0.6584 - lr: 1.5625e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4153 - accuracy: 0.8543 - val_loss: 1.2566 - val_accuracy: 0.6543 - lr: 1.5625e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4121 - accuracy: 0.8585 - val_loss: 1.2660 - val_accuracy: 0.6564 - lr: 1.5625e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4068 - accuracy: 0.8667 - val_loss: 1.2712 - val_accuracy: 0.6584 - lr: 1.5625e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8636 - val_loss: 1.2473 - val_accuracy: 0.6584 - lr: 1.5625e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4252 - accuracy: 0.8662 - val_loss: 1.2474 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3832 - accuracy: 0.8734 - val_loss: 1.2153 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3931 - accuracy: 0.8662 - val_loss: 1.2031 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4121 - accuracy: 0.8569 - val_loss: 1.2147 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3869 - accuracy: 0.8662 - val_loss: 1.2042 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3930 - accuracy: 0.8677 - val_loss: 1.2196 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4002 - accuracy: 0.8646 - val_loss: 1.2282 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.8739 - val_loss: 1.2200 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3926 - accuracy: 0.8672 - val_loss: 1.2199 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3973 - accuracy: 0.8641 - val_loss: 1.2082 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4023 - accuracy: 0.8621 - val_loss: 1.2169 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3864 - accuracy: 0.8796 - val_loss: 1.2226 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8616 - val_loss: 1.2260 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.8718 - val_loss: 1.2175 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3964 - accuracy: 0.8595 - val_loss: 1.2232 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3886 - accuracy: 0.8667 - val_loss: 1.2108 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3893 - accuracy: 0.8590 - val_loss: 1.2159 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3954 - accuracy: 0.8641 - val_loss: 1.2086 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4006 - accuracy: 0.8652 - val_loss: 1.2249 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3781 - accuracy: 0.8734 - val_loss: 1.2271 - val_accuracy: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 1/200\n",
            "31/31 [==============================] - 2s 26ms/step - loss: 2.0480 - accuracy: 0.3546 - val_loss: 2.1644 - val_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.7646 - accuracy: 0.3968 - val_loss: 2.0934 - val_accuracy: 0.3621 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.5880 - accuracy: 0.4683 - val_loss: 1.9131 - val_accuracy: 0.4012 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.5396 - accuracy: 0.4817 - val_loss: 1.9079 - val_accuracy: 0.4012 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.4791 - accuracy: 0.5018 - val_loss: 1.9309 - val_accuracy: 0.4280 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.3787 - accuracy: 0.5347 - val_loss: 1.7454 - val_accuracy: 0.4218 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.2963 - accuracy: 0.5517 - val_loss: 1.6544 - val_accuracy: 0.4650 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2483 - accuracy: 0.5553 - val_loss: 1.6669 - val_accuracy: 0.4918 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.1669 - accuracy: 0.5914 - val_loss: 1.5587 - val_accuracy: 0.4938 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.1260 - accuracy: 0.5986 - val_loss: 1.4032 - val_accuracy: 0.5267 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.0627 - accuracy: 0.6315 - val_loss: 1.4792 - val_accuracy: 0.5226 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0494 - accuracy: 0.6418 - val_loss: 1.2767 - val_accuracy: 0.5453 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0493 - accuracy: 0.6392 - val_loss: 1.2802 - val_accuracy: 0.5597 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.0729 - accuracy: 0.6176 - val_loss: 1.3492 - val_accuracy: 0.5535 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9557 - accuracy: 0.6624 - val_loss: 1.2098 - val_accuracy: 0.6008 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9969 - accuracy: 0.6639 - val_loss: 1.2596 - val_accuracy: 0.5761 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9588 - accuracy: 0.6644 - val_loss: 1.4568 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9481 - accuracy: 0.6758 - val_loss: 1.2057 - val_accuracy: 0.5988 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8889 - accuracy: 0.6886 - val_loss: 1.0530 - val_accuracy: 0.6317 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9198 - accuracy: 0.6876 - val_loss: 1.1474 - val_accuracy: 0.6214 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8703 - accuracy: 0.6989 - val_loss: 1.1452 - val_accuracy: 0.6049 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8853 - accuracy: 0.6845 - val_loss: 1.2768 - val_accuracy: 0.6008 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8637 - accuracy: 0.6953 - val_loss: 1.1589 - val_accuracy: 0.6029 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.8054 - accuracy: 0.7210 - val_loss: 1.3757 - val_accuracy: 0.5988 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.7530 - accuracy: 0.7391 - val_loss: 1.1944 - val_accuracy: 0.6276 - lr: 5.0000e-04\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.7199 - accuracy: 0.7494 - val_loss: 1.2013 - val_accuracy: 0.6132 - lr: 5.0000e-04\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6856 - accuracy: 0.7627 - val_loss: 1.1022 - val_accuracy: 0.6379 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6718 - accuracy: 0.7694 - val_loss: 1.1847 - val_accuracy: 0.6255 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6379 - accuracy: 0.7833 - val_loss: 1.0599 - val_accuracy: 0.6584 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6434 - accuracy: 0.7730 - val_loss: 1.1356 - val_accuracy: 0.6276 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6216 - accuracy: 0.7771 - val_loss: 1.0745 - val_accuracy: 0.6399 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6340 - accuracy: 0.7792 - val_loss: 1.1167 - val_accuracy: 0.6193 - lr: 5.0000e-04\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6005 - accuracy: 0.7957 - val_loss: 1.1919 - val_accuracy: 0.6276 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6000 - accuracy: 0.7936 - val_loss: 1.0287 - val_accuracy: 0.6543 - lr: 5.0000e-04\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5718 - accuracy: 0.7905 - val_loss: 1.0659 - val_accuracy: 0.6605 - lr: 2.5000e-04\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5426 - accuracy: 0.8147 - val_loss: 1.1176 - val_accuracy: 0.6543 - lr: 2.5000e-04\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5429 - accuracy: 0.8142 - val_loss: 1.1166 - val_accuracy: 0.6502 - lr: 2.5000e-04\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5351 - accuracy: 0.8101 - val_loss: 1.0737 - val_accuracy: 0.6523 - lr: 2.5000e-04\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5329 - accuracy: 0.8194 - val_loss: 1.0765 - val_accuracy: 0.6543 - lr: 2.5000e-04\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5171 - accuracy: 0.8276 - val_loss: 1.0665 - val_accuracy: 0.6523 - lr: 2.5000e-04\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4800 - accuracy: 0.8405 - val_loss: 1.1126 - val_accuracy: 0.6399 - lr: 1.2500e-04\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4668 - accuracy: 0.8384 - val_loss: 1.0829 - val_accuracy: 0.6646 - lr: 1.2500e-04\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.4771 - accuracy: 0.8312 - val_loss: 1.1168 - val_accuracy: 0.6543 - lr: 1.2500e-04\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.4908 - accuracy: 0.8327 - val_loss: 1.0959 - val_accuracy: 0.6667 - lr: 1.2500e-04\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.4662 - accuracy: 0.8296 - val_loss: 1.0999 - val_accuracy: 0.6667 - lr: 1.2500e-04\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.4678 - accuracy: 0.8338 - val_loss: 1.1358 - val_accuracy: 0.6481 - lr: 1.2500e-04\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.4550 - accuracy: 0.8399 - val_loss: 1.1444 - val_accuracy: 0.6543 - lr: 1.2500e-04\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4496 - accuracy: 0.8394 - val_loss: 1.1582 - val_accuracy: 0.6523 - lr: 1.2500e-04\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4596 - accuracy: 0.8338 - val_loss: 1.1436 - val_accuracy: 0.6564 - lr: 1.2500e-04\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4457 - accuracy: 0.8420 - val_loss: 1.1428 - val_accuracy: 0.6564 - lr: 6.2500e-05\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4181 - accuracy: 0.8585 - val_loss: 1.1357 - val_accuracy: 0.6502 - lr: 6.2500e-05\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4338 - accuracy: 0.8538 - val_loss: 1.1220 - val_accuracy: 0.6564 - lr: 6.2500e-05\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4334 - accuracy: 0.8518 - val_loss: 1.1131 - val_accuracy: 0.6646 - lr: 6.2500e-05\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4515 - accuracy: 0.8456 - val_loss: 1.1061 - val_accuracy: 0.6502 - lr: 6.2500e-05\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4182 - accuracy: 0.8559 - val_loss: 1.1180 - val_accuracy: 0.6502 - lr: 3.1250e-05\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4226 - accuracy: 0.8507 - val_loss: 1.1206 - val_accuracy: 0.6523 - lr: 3.1250e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3956 - accuracy: 0.8641 - val_loss: 1.1325 - val_accuracy: 0.6461 - lr: 3.1250e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4057 - accuracy: 0.8621 - val_loss: 1.1273 - val_accuracy: 0.6481 - lr: 3.1250e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4173 - accuracy: 0.8641 - val_loss: 1.1140 - val_accuracy: 0.6420 - lr: 3.1250e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4204 - accuracy: 0.8610 - val_loss: 1.1275 - val_accuracy: 0.6399 - lr: 1.5625e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4019 - accuracy: 0.8580 - val_loss: 1.1576 - val_accuracy: 0.6440 - lr: 1.5625e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3876 - accuracy: 0.8672 - val_loss: 1.1780 - val_accuracy: 0.6379 - lr: 1.5625e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4017 - accuracy: 0.8595 - val_loss: 1.1407 - val_accuracy: 0.6523 - lr: 1.5625e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3971 - accuracy: 0.8652 - val_loss: 1.1384 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3883 - accuracy: 0.8657 - val_loss: 1.1411 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4031 - accuracy: 0.8554 - val_loss: 1.1733 - val_accuracy: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3967 - accuracy: 0.8616 - val_loss: 1.1635 - val_accuracy: 0.6461 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3913 - accuracy: 0.8688 - val_loss: 1.1499 - val_accuracy: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4242 - accuracy: 0.8580 - val_loss: 1.1408 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3918 - accuracy: 0.8677 - val_loss: 1.1458 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3980 - accuracy: 0.8641 - val_loss: 1.1302 - val_accuracy: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3936 - accuracy: 0.8641 - val_loss: 1.1275 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3974 - accuracy: 0.8492 - val_loss: 1.1404 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3867 - accuracy: 0.8698 - val_loss: 1.1278 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4055 - accuracy: 0.8646 - val_loss: 1.1256 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3964 - accuracy: 0.8616 - val_loss: 1.1093 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3905 - accuracy: 0.8667 - val_loss: 1.1116 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3961 - accuracy: 0.8621 - val_loss: 1.1208 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3923 - accuracy: 0.8718 - val_loss: 1.1160 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3865 - accuracy: 0.8641 - val_loss: 1.1136 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3910 - accuracy: 0.8641 - val_loss: 1.1192 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4141 - accuracy: 0.8580 - val_loss: 1.1417 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.4106 - accuracy: 0.8523 - val_loss: 1.1450 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3946 - accuracy: 0.8708 - val_loss: 1.1377 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.3984 - accuracy: 0.8657 - val_loss: 1.1328 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3975 - accuracy: 0.8652 - val_loss: 1.1268 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3933 - accuracy: 0.8595 - val_loss: 1.1429 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8621 - val_loss: 1.1383 - val_accuracy: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3899 - accuracy: 0.8667 - val_loss: 1.1279 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3853 - accuracy: 0.8739 - val_loss: 1.1150 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3738 - accuracy: 0.8744 - val_loss: 1.1240 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.8760 - val_loss: 1.1273 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3814 - accuracy: 0.8724 - val_loss: 1.1243 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3930 - accuracy: 0.8616 - val_loss: 1.1372 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 1/200\n",
            "31/31 [==============================] - 2s 27ms/step - loss: 2.0715 - accuracy: 0.3654 - val_loss: 2.1569 - val_accuracy: 0.3889 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.7619 - accuracy: 0.4195 - val_loss: 2.0958 - val_accuracy: 0.4444 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.5573 - accuracy: 0.4771 - val_loss: 1.9953 - val_accuracy: 0.4486 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.3993 - accuracy: 0.5214 - val_loss: 1.8964 - val_accuracy: 0.4424 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.3213 - accuracy: 0.5497 - val_loss: 1.7547 - val_accuracy: 0.4424 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.2915 - accuracy: 0.5533 - val_loss: 1.7200 - val_accuracy: 0.4609 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.2443 - accuracy: 0.5800 - val_loss: 1.8386 - val_accuracy: 0.4115 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2125 - accuracy: 0.6022 - val_loss: 1.5877 - val_accuracy: 0.5041 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.1509 - accuracy: 0.6217 - val_loss: 1.4893 - val_accuracy: 0.5082 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.1266 - accuracy: 0.6058 - val_loss: 1.6478 - val_accuracy: 0.4547 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0694 - accuracy: 0.6433 - val_loss: 1.4507 - val_accuracy: 0.4897 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0382 - accuracy: 0.6480 - val_loss: 1.5151 - val_accuracy: 0.4856 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0016 - accuracy: 0.6423 - val_loss: 1.3393 - val_accuracy: 0.5391 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9426 - accuracy: 0.6835 - val_loss: 1.4928 - val_accuracy: 0.5206 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9785 - accuracy: 0.6670 - val_loss: 1.3508 - val_accuracy: 0.5556 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9549 - accuracy: 0.6783 - val_loss: 1.2964 - val_accuracy: 0.5412 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8918 - accuracy: 0.6984 - val_loss: 1.1602 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8795 - accuracy: 0.6989 - val_loss: 1.2905 - val_accuracy: 0.5905 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8816 - accuracy: 0.6999 - val_loss: 1.3445 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8631 - accuracy: 0.6974 - val_loss: 1.1695 - val_accuracy: 0.6091 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8101 - accuracy: 0.7092 - val_loss: 1.0474 - val_accuracy: 0.6481 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8410 - accuracy: 0.7118 - val_loss: 1.3715 - val_accuracy: 0.5802 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9244 - accuracy: 0.6850 - val_loss: 1.3074 - val_accuracy: 0.5864 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8567 - accuracy: 0.7036 - val_loss: 1.5196 - val_accuracy: 0.5720 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8265 - accuracy: 0.7205 - val_loss: 1.2434 - val_accuracy: 0.6173 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8121 - accuracy: 0.7169 - val_loss: 1.1360 - val_accuracy: 0.6461 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.7582 - accuracy: 0.7437 - val_loss: 1.2421 - val_accuracy: 0.6214 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6966 - accuracy: 0.7627 - val_loss: 1.1131 - val_accuracy: 0.6584 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.6622 - accuracy: 0.7715 - val_loss: 1.2149 - val_accuracy: 0.6358 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6500 - accuracy: 0.7818 - val_loss: 1.2397 - val_accuracy: 0.6214 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6366 - accuracy: 0.7766 - val_loss: 1.2666 - val_accuracy: 0.6317 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6143 - accuracy: 0.7828 - val_loss: 1.2504 - val_accuracy: 0.6296 - lr: 5.0000e-04\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6097 - accuracy: 0.7931 - val_loss: 1.3633 - val_accuracy: 0.6296 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.5779 - accuracy: 0.8013 - val_loss: 1.3087 - val_accuracy: 0.6502 - lr: 2.5000e-04\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5689 - accuracy: 0.7988 - val_loss: 1.2023 - val_accuracy: 0.6708 - lr: 2.5000e-04\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5537 - accuracy: 0.8116 - val_loss: 1.1745 - val_accuracy: 0.6728 - lr: 2.5000e-04\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5285 - accuracy: 0.8199 - val_loss: 1.1645 - val_accuracy: 0.6564 - lr: 2.5000e-04\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5261 - accuracy: 0.8235 - val_loss: 1.1624 - val_accuracy: 0.6728 - lr: 2.5000e-04\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5186 - accuracy: 0.8214 - val_loss: 1.1823 - val_accuracy: 0.6523 - lr: 2.5000e-04\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5328 - accuracy: 0.8214 - val_loss: 1.1644 - val_accuracy: 0.6564 - lr: 2.5000e-04\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5020 - accuracy: 0.8178 - val_loss: 1.1672 - val_accuracy: 0.6564 - lr: 2.5000e-04\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4844 - accuracy: 0.8353 - val_loss: 1.1801 - val_accuracy: 0.6543 - lr: 1.2500e-04\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.4819 - accuracy: 0.8374 - val_loss: 1.2058 - val_accuracy: 0.6502 - lr: 1.2500e-04\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4773 - accuracy: 0.8374 - val_loss: 1.1672 - val_accuracy: 0.6543 - lr: 1.2500e-04\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4586 - accuracy: 0.8430 - val_loss: 1.1597 - val_accuracy: 0.6584 - lr: 1.2500e-04\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4634 - accuracy: 0.8461 - val_loss: 1.2028 - val_accuracy: 0.6399 - lr: 1.2500e-04\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4749 - accuracy: 0.8430 - val_loss: 1.1980 - val_accuracy: 0.6440 - lr: 6.2500e-05\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4719 - accuracy: 0.8430 - val_loss: 1.1779 - val_accuracy: 0.6605 - lr: 6.2500e-05\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4454 - accuracy: 0.8482 - val_loss: 1.1782 - val_accuracy: 0.6523 - lr: 6.2500e-05\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4542 - accuracy: 0.8441 - val_loss: 1.1754 - val_accuracy: 0.6605 - lr: 6.2500e-05\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4330 - accuracy: 0.8549 - val_loss: 1.1914 - val_accuracy: 0.6667 - lr: 6.2500e-05\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4415 - accuracy: 0.8487 - val_loss: 1.1851 - val_accuracy: 0.6646 - lr: 3.1250e-05\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4377 - accuracy: 0.8456 - val_loss: 1.2048 - val_accuracy: 0.6605 - lr: 3.1250e-05\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4428 - accuracy: 0.8430 - val_loss: 1.1938 - val_accuracy: 0.6626 - lr: 3.1250e-05\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4265 - accuracy: 0.8610 - val_loss: 1.1718 - val_accuracy: 0.6687 - lr: 3.1250e-05\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4367 - accuracy: 0.8507 - val_loss: 1.1723 - val_accuracy: 0.6646 - lr: 3.1250e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4444 - accuracy: 0.8399 - val_loss: 1.1745 - val_accuracy: 0.6646 - lr: 1.5625e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4249 - accuracy: 0.8523 - val_loss: 1.1797 - val_accuracy: 0.6543 - lr: 1.5625e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4518 - accuracy: 0.8528 - val_loss: 1.1870 - val_accuracy: 0.6605 - lr: 1.5625e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4264 - accuracy: 0.8533 - val_loss: 1.1698 - val_accuracy: 0.6667 - lr: 1.5625e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4258 - accuracy: 0.8523 - val_loss: 1.1831 - val_accuracy: 0.6626 - lr: 1.5625e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4318 - accuracy: 0.8533 - val_loss: 1.1832 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.8420 - val_loss: 1.2001 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4074 - accuracy: 0.8616 - val_loss: 1.2003 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4082 - accuracy: 0.8595 - val_loss: 1.1915 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4308 - accuracy: 0.8559 - val_loss: 1.1780 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4299 - accuracy: 0.8569 - val_loss: 1.1791 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4157 - accuracy: 0.8569 - val_loss: 1.1913 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4271 - accuracy: 0.8610 - val_loss: 1.1979 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4210 - accuracy: 0.8559 - val_loss: 1.1946 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4299 - accuracy: 0.8569 - val_loss: 1.1992 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4222 - accuracy: 0.8621 - val_loss: 1.1886 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4011 - accuracy: 0.8631 - val_loss: 1.1788 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4274 - accuracy: 0.8538 - val_loss: 1.1779 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4180 - accuracy: 0.8580 - val_loss: 1.1873 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4041 - accuracy: 0.8641 - val_loss: 1.2015 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4243 - accuracy: 0.8538 - val_loss: 1.1944 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.8631 - val_loss: 1.1950 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4321 - accuracy: 0.8513 - val_loss: 1.1967 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4082 - accuracy: 0.8631 - val_loss: 1.1954 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4081 - accuracy: 0.8636 - val_loss: 1.1903 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.8492 - val_loss: 1.1909 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4159 - accuracy: 0.8600 - val_loss: 1.1988 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4046 - accuracy: 0.8626 - val_loss: 1.1941 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4063 - accuracy: 0.8610 - val_loss: 1.1966 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4155 - accuracy: 0.8605 - val_loss: 1.1909 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 1/200\n",
            "31/31 [==============================] - 3s 41ms/step - loss: 2.0381 - accuracy: 0.3464 - val_loss: 2.1511 - val_accuracy: 0.4033 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.7841 - accuracy: 0.4236 - val_loss: 1.9862 - val_accuracy: 0.4136 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.5682 - accuracy: 0.4647 - val_loss: 1.8922 - val_accuracy: 0.4095 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.4572 - accuracy: 0.4992 - val_loss: 1.7499 - val_accuracy: 0.4506 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.3751 - accuracy: 0.5203 - val_loss: 1.6858 - val_accuracy: 0.4671 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.3467 - accuracy: 0.5378 - val_loss: 1.6918 - val_accuracy: 0.4362 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2426 - accuracy: 0.5790 - val_loss: 1.6654 - val_accuracy: 0.4218 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2405 - accuracy: 0.5697 - val_loss: 1.6318 - val_accuracy: 0.4609 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.2395 - accuracy: 0.5759 - val_loss: 1.5457 - val_accuracy: 0.4877 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.1346 - accuracy: 0.6125 - val_loss: 1.4076 - val_accuracy: 0.5288 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.1150 - accuracy: 0.6212 - val_loss: 1.4268 - val_accuracy: 0.5267 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0239 - accuracy: 0.6408 - val_loss: 1.3959 - val_accuracy: 0.5329 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0521 - accuracy: 0.6423 - val_loss: 1.4686 - val_accuracy: 0.5370 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0282 - accuracy: 0.6253 - val_loss: 1.3262 - val_accuracy: 0.5453 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9856 - accuracy: 0.6511 - val_loss: 1.3518 - val_accuracy: 0.5391 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.9532 - accuracy: 0.6773 - val_loss: 1.5666 - val_accuracy: 0.5103 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9759 - accuracy: 0.6680 - val_loss: 1.4322 - val_accuracy: 0.5597 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9055 - accuracy: 0.6845 - val_loss: 1.5758 - val_accuracy: 0.5247 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.8605 - accuracy: 0.6999 - val_loss: 1.2550 - val_accuracy: 0.5947 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9194 - accuracy: 0.6876 - val_loss: 1.1678 - val_accuracy: 0.6091 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.9158 - accuracy: 0.6840 - val_loss: 1.1820 - val_accuracy: 0.6399 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8737 - accuracy: 0.7108 - val_loss: 1.1875 - val_accuracy: 0.6008 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8962 - accuracy: 0.6938 - val_loss: 1.2630 - val_accuracy: 0.6008 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8431 - accuracy: 0.7082 - val_loss: 1.4882 - val_accuracy: 0.5638 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8568 - accuracy: 0.7046 - val_loss: 1.2419 - val_accuracy: 0.5905 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8649 - accuracy: 0.6907 - val_loss: 1.4667 - val_accuracy: 0.5926 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7637 - accuracy: 0.7422 - val_loss: 1.1362 - val_accuracy: 0.6399 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.7009 - accuracy: 0.7540 - val_loss: 1.1698 - val_accuracy: 0.6337 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7066 - accuracy: 0.7499 - val_loss: 1.1361 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6801 - accuracy: 0.7658 - val_loss: 1.0732 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6511 - accuracy: 0.7751 - val_loss: 1.1836 - val_accuracy: 0.6481 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6747 - accuracy: 0.7699 - val_loss: 1.1984 - val_accuracy: 0.6358 - lr: 5.0000e-04\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.6460 - accuracy: 0.7823 - val_loss: 1.4422 - val_accuracy: 0.6173 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6067 - accuracy: 0.7885 - val_loss: 1.3489 - val_accuracy: 0.6235 - lr: 5.0000e-04\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5963 - accuracy: 0.7957 - val_loss: 1.3165 - val_accuracy: 0.6461 - lr: 2.5000e-04\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5956 - accuracy: 0.7864 - val_loss: 1.2496 - val_accuracy: 0.6461 - lr: 2.5000e-04\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5636 - accuracy: 0.8070 - val_loss: 1.1981 - val_accuracy: 0.6440 - lr: 2.5000e-04\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5473 - accuracy: 0.8065 - val_loss: 1.2069 - val_accuracy: 0.6543 - lr: 2.5000e-04\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5544 - accuracy: 0.8106 - val_loss: 1.2214 - val_accuracy: 0.6420 - lr: 2.5000e-04\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5413 - accuracy: 0.8044 - val_loss: 1.2165 - val_accuracy: 0.6523 - lr: 1.2500e-04\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5338 - accuracy: 0.8106 - val_loss: 1.1754 - val_accuracy: 0.6626 - lr: 1.2500e-04\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5270 - accuracy: 0.8163 - val_loss: 1.1749 - val_accuracy: 0.6626 - lr: 1.2500e-04\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5248 - accuracy: 0.8219 - val_loss: 1.2458 - val_accuracy: 0.6502 - lr: 1.2500e-04\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5100 - accuracy: 0.8281 - val_loss: 1.2290 - val_accuracy: 0.6564 - lr: 1.2500e-04\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4858 - accuracy: 0.8317 - val_loss: 1.1908 - val_accuracy: 0.6626 - lr: 1.2500e-04\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5004 - accuracy: 0.8296 - val_loss: 1.1983 - val_accuracy: 0.6584 - lr: 1.2500e-04\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4902 - accuracy: 0.8317 - val_loss: 1.1899 - val_accuracy: 0.6605 - lr: 6.2500e-05\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4603 - accuracy: 0.8379 - val_loss: 1.1698 - val_accuracy: 0.6626 - lr: 6.2500e-05\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4854 - accuracy: 0.8281 - val_loss: 1.2343 - val_accuracy: 0.6584 - lr: 6.2500e-05\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4606 - accuracy: 0.8399 - val_loss: 1.2398 - val_accuracy: 0.6564 - lr: 6.2500e-05\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4659 - accuracy: 0.8379 - val_loss: 1.2387 - val_accuracy: 0.6584 - lr: 6.2500e-05\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4604 - accuracy: 0.8456 - val_loss: 1.2421 - val_accuracy: 0.6523 - lr: 3.1250e-05\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4517 - accuracy: 0.8456 - val_loss: 1.2498 - val_accuracy: 0.6584 - lr: 3.1250e-05\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4570 - accuracy: 0.8389 - val_loss: 1.2643 - val_accuracy: 0.6564 - lr: 3.1250e-05\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4556 - accuracy: 0.8492 - val_loss: 1.2661 - val_accuracy: 0.6564 - lr: 3.1250e-05\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4565 - accuracy: 0.8543 - val_loss: 1.2735 - val_accuracy: 0.6523 - lr: 3.1250e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4533 - accuracy: 0.8492 - val_loss: 1.2752 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4725 - accuracy: 0.8363 - val_loss: 1.2819 - val_accuracy: 0.6461 - lr: 1.5625e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4621 - accuracy: 0.8343 - val_loss: 1.2723 - val_accuracy: 0.6523 - lr: 1.5625e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4373 - accuracy: 0.8456 - val_loss: 1.2670 - val_accuracy: 0.6523 - lr: 1.5625e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4414 - accuracy: 0.8405 - val_loss: 1.2538 - val_accuracy: 0.6667 - lr: 1.5625e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4510 - accuracy: 0.8471 - val_loss: 1.2610 - val_accuracy: 0.6605 - lr: 1.5625e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4441 - accuracy: 0.8487 - val_loss: 1.2447 - val_accuracy: 0.6605 - lr: 1.5625e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.8564 - val_loss: 1.2381 - val_accuracy: 0.6584 - lr: 1.5625e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4429 - accuracy: 0.8528 - val_loss: 1.2331 - val_accuracy: 0.6626 - lr: 1.5625e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4595 - accuracy: 0.8358 - val_loss: 1.2235 - val_accuracy: 0.6667 - lr: 1.5625e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4424 - accuracy: 0.8487 - val_loss: 1.2388 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4602 - accuracy: 0.8348 - val_loss: 1.2328 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4298 - accuracy: 0.8559 - val_loss: 1.2273 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4454 - accuracy: 0.8533 - val_loss: 1.2219 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4508 - accuracy: 0.8471 - val_loss: 1.2253 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4487 - accuracy: 0.8420 - val_loss: 1.2406 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4309 - accuracy: 0.8482 - val_loss: 1.2483 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4321 - accuracy: 0.8554 - val_loss: 1.2450 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4361 - accuracy: 0.8523 - val_loss: 1.2362 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4426 - accuracy: 0.8430 - val_loss: 1.2470 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4365 - accuracy: 0.8492 - val_loss: 1.2396 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4450 - accuracy: 0.8461 - val_loss: 1.2561 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4502 - accuracy: 0.8394 - val_loss: 1.2511 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4436 - accuracy: 0.8482 - val_loss: 1.2415 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.8595 - val_loss: 1.2492 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.8513 - val_loss: 1.2758 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4485 - accuracy: 0.8410 - val_loss: 1.2662 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4232 - accuracy: 0.8559 - val_loss: 1.2502 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4332 - accuracy: 0.8461 - val_loss: 1.2538 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4317 - accuracy: 0.8543 - val_loss: 1.2545 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4356 - accuracy: 0.8518 - val_loss: 1.2807 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4342 - accuracy: 0.8559 - val_loss: 1.2815 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.8605 - val_loss: 1.2713 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4451 - accuracy: 0.8482 - val_loss: 1.2694 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4258 - accuracy: 0.8590 - val_loss: 1.2664 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8543 - val_loss: 1.2522 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4357 - accuracy: 0.8533 - val_loss: 1.2424 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4191 - accuracy: 0.8523 - val_loss: 1.2503 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4243 - accuracy: 0.8538 - val_loss: 1.2442 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4319 - accuracy: 0.8574 - val_loss: 1.2457 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4236 - accuracy: 0.8543 - val_loss: 1.2455 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4225 - accuracy: 0.8497 - val_loss: 1.2503 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4409 - accuracy: 0.8543 - val_loss: 1.2417 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.8574 - val_loss: 1.2435 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4271 - accuracy: 0.8487 - val_loss: 1.2408 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4602 - accuracy: 0.8482 - val_loss: 1.2461 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4238 - accuracy: 0.8523 - val_loss: 1.2461 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4420 - accuracy: 0.8502 - val_loss: 1.2559 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4422 - accuracy: 0.8554 - val_loss: 1.2692 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4187 - accuracy: 0.8564 - val_loss: 1.2725 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4487 - accuracy: 0.8405 - val_loss: 1.2806 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4344 - accuracy: 0.8497 - val_loss: 1.2660 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4377 - accuracy: 0.8549 - val_loss: 1.2728 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4558 - accuracy: 0.8466 - val_loss: 1.2682 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4059 - accuracy: 0.8590 - val_loss: 1.2731 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4251 - accuracy: 0.8610 - val_loss: 1.2648 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4270 - accuracy: 0.8631 - val_loss: 1.2766 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4236 - accuracy: 0.8538 - val_loss: 1.2719 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4306 - accuracy: 0.8528 - val_loss: 1.2898 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4246 - accuracy: 0.8518 - val_loss: 1.2679 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4131 - accuracy: 0.8590 - val_loss: 1.2559 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4219 - accuracy: 0.8543 - val_loss: 1.2520 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4314 - accuracy: 0.8554 - val_loss: 1.2465 - val_accuracy: 0.6626 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4330 - accuracy: 0.8549 - val_loss: 1.2434 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4153 - accuracy: 0.8605 - val_loss: 1.2423 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4192 - accuracy: 0.8636 - val_loss: 1.2514 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.8641 - val_loss: 1.2475 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4313 - accuracy: 0.8533 - val_loss: 1.2598 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4386 - accuracy: 0.8513 - val_loss: 1.2659 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4190 - accuracy: 0.8564 - val_loss: 1.2505 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4077 - accuracy: 0.8657 - val_loss: 1.2466 - val_accuracy: 0.6605 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.8652 - val_loss: 1.2645 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4039 - accuracy: 0.8657 - val_loss: 1.2887 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4197 - accuracy: 0.8543 - val_loss: 1.2901 - val_accuracy: 0.6584 - lr: 1.0000e-05\n",
            "Epoch 1/200\n",
            "31/31 [==============================] - 2s 28ms/step - loss: 2.0453 - accuracy: 0.3500 - val_loss: 2.2117 - val_accuracy: 0.3951 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 1.7297 - accuracy: 0.4241 - val_loss: 2.1040 - val_accuracy: 0.3765 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 1.5766 - accuracy: 0.4730 - val_loss: 1.9481 - val_accuracy: 0.4300 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 1.4917 - accuracy: 0.4915 - val_loss: 1.8841 - val_accuracy: 0.4424 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 1.3707 - accuracy: 0.5389 - val_loss: 1.7558 - val_accuracy: 0.4547 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 1.3737 - accuracy: 0.5219 - val_loss: 1.9690 - val_accuracy: 0.3436 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.2956 - accuracy: 0.5656 - val_loss: 1.7924 - val_accuracy: 0.4156 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 1.2398 - accuracy: 0.5656 - val_loss: 1.6252 - val_accuracy: 0.4588 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.1703 - accuracy: 0.5908 - val_loss: 1.5172 - val_accuracy: 0.5144 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2125 - accuracy: 0.5934 - val_loss: 1.6423 - val_accuracy: 0.4691 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.1219 - accuracy: 0.6135 - val_loss: 1.5368 - val_accuracy: 0.4897 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.1538 - accuracy: 0.5975 - val_loss: 1.6736 - val_accuracy: 0.3807 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.0948 - accuracy: 0.6089 - val_loss: 1.6919 - val_accuracy: 0.4959 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.0597 - accuracy: 0.6438 - val_loss: 1.2495 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9500 - accuracy: 0.6758 - val_loss: 1.2962 - val_accuracy: 0.5844 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9640 - accuracy: 0.6675 - val_loss: 1.2117 - val_accuracy: 0.5844 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.9478 - accuracy: 0.6778 - val_loss: 1.3989 - val_accuracy: 0.5514 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.9163 - accuracy: 0.6897 - val_loss: 1.1585 - val_accuracy: 0.6070 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9798 - accuracy: 0.6644 - val_loss: 1.1355 - val_accuracy: 0.6276 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9344 - accuracy: 0.6732 - val_loss: 1.1336 - val_accuracy: 0.6193 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8582 - accuracy: 0.7015 - val_loss: 1.5438 - val_accuracy: 0.5165 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.8929 - accuracy: 0.6871 - val_loss: 1.2658 - val_accuracy: 0.5864 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8401 - accuracy: 0.7025 - val_loss: 1.3474 - val_accuracy: 0.5844 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8510 - accuracy: 0.7046 - val_loss: 1.2209 - val_accuracy: 0.6173 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8002 - accuracy: 0.7241 - val_loss: 1.0495 - val_accuracy: 0.6667 - lr: 5.0000e-04\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7475 - accuracy: 0.7339 - val_loss: 1.0392 - val_accuracy: 0.6461 - lr: 5.0000e-04\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7147 - accuracy: 0.7442 - val_loss: 1.0557 - val_accuracy: 0.6502 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6944 - accuracy: 0.7602 - val_loss: 1.0522 - val_accuracy: 0.6543 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6797 - accuracy: 0.7586 - val_loss: 1.0173 - val_accuracy: 0.6872 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.6925 - accuracy: 0.7602 - val_loss: 1.0336 - val_accuracy: 0.6811 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6727 - accuracy: 0.7648 - val_loss: 1.0884 - val_accuracy: 0.6337 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6569 - accuracy: 0.7591 - val_loss: 1.0878 - val_accuracy: 0.6626 - lr: 5.0000e-04\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6213 - accuracy: 0.7730 - val_loss: 1.1706 - val_accuracy: 0.6461 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5908 - accuracy: 0.7962 - val_loss: 1.0437 - val_accuracy: 0.6646 - lr: 5.0000e-04\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5971 - accuracy: 0.7885 - val_loss: 1.0729 - val_accuracy: 0.6626 - lr: 2.5000e-04\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5551 - accuracy: 0.8121 - val_loss: 1.1551 - val_accuracy: 0.6626 - lr: 2.5000e-04\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5459 - accuracy: 0.8111 - val_loss: 1.1179 - val_accuracy: 0.6749 - lr: 2.5000e-04\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5352 - accuracy: 0.8147 - val_loss: 1.1635 - val_accuracy: 0.6564 - lr: 2.5000e-04\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5238 - accuracy: 0.8194 - val_loss: 1.1328 - val_accuracy: 0.6687 - lr: 2.5000e-04\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5252 - accuracy: 0.8137 - val_loss: 1.1286 - val_accuracy: 0.6564 - lr: 1.2500e-04\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5178 - accuracy: 0.8163 - val_loss: 1.0922 - val_accuracy: 0.6605 - lr: 1.2500e-04\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5046 - accuracy: 0.8348 - val_loss: 1.1450 - val_accuracy: 0.6502 - lr: 1.2500e-04\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5049 - accuracy: 0.8266 - val_loss: 1.1516 - val_accuracy: 0.6523 - lr: 1.2500e-04\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4964 - accuracy: 0.8271 - val_loss: 1.1439 - val_accuracy: 0.6626 - lr: 1.2500e-04\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.8405 - val_loss: 1.1490 - val_accuracy: 0.6543 - lr: 6.2500e-05\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4964 - accuracy: 0.8291 - val_loss: 1.1343 - val_accuracy: 0.6543 - lr: 6.2500e-05\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.8338 - val_loss: 1.1785 - val_accuracy: 0.6502 - lr: 6.2500e-05\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4841 - accuracy: 0.8348 - val_loss: 1.1651 - val_accuracy: 0.6461 - lr: 6.2500e-05\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4789 - accuracy: 0.8405 - val_loss: 1.1604 - val_accuracy: 0.6440 - lr: 6.2500e-05\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.8358 - val_loss: 1.1405 - val_accuracy: 0.6543 - lr: 3.1250e-05\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4748 - accuracy: 0.8327 - val_loss: 1.1677 - val_accuracy: 0.6481 - lr: 3.1250e-05\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4477 - accuracy: 0.8471 - val_loss: 1.1955 - val_accuracy: 0.6481 - lr: 3.1250e-05\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4764 - accuracy: 0.8312 - val_loss: 1.1907 - val_accuracy: 0.6440 - lr: 3.1250e-05\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4399 - accuracy: 0.8477 - val_loss: 1.1683 - val_accuracy: 0.6481 - lr: 3.1250e-05\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4675 - accuracy: 0.8410 - val_loss: 1.1778 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4590 - accuracy: 0.8430 - val_loss: 1.1872 - val_accuracy: 0.6481 - lr: 1.5625e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4554 - accuracy: 0.8415 - val_loss: 1.1738 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.8471 - val_loss: 1.1817 - val_accuracy: 0.6461 - lr: 1.5625e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.4532 - accuracy: 0.8502 - val_loss: 1.1959 - val_accuracy: 0.6502 - lr: 1.5625e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4482 - accuracy: 0.8477 - val_loss: 1.1725 - val_accuracy: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4532 - accuracy: 0.8477 - val_loss: 1.1814 - val_accuracy: 0.6461 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4347 - accuracy: 0.8513 - val_loss: 1.1715 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.8466 - val_loss: 1.2065 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4535 - accuracy: 0.8477 - val_loss: 1.2176 - val_accuracy: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4440 - accuracy: 0.8471 - val_loss: 1.2215 - val_accuracy: 0.6481 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4423 - accuracy: 0.8497 - val_loss: 1.2080 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4523 - accuracy: 0.8507 - val_loss: 1.1911 - val_accuracy: 0.6481 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4418 - accuracy: 0.8523 - val_loss: 1.2195 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4515 - accuracy: 0.8549 - val_loss: 1.2176 - val_accuracy: 0.6481 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4238 - accuracy: 0.8543 - val_loss: 1.2212 - val_accuracy: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4337 - accuracy: 0.8528 - val_loss: 1.1954 - val_accuracy: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4469 - accuracy: 0.8518 - val_loss: 1.2125 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4395 - accuracy: 0.8518 - val_loss: 1.2035 - val_accuracy: 0.6481 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4598 - accuracy: 0.8446 - val_loss: 1.2160 - val_accuracy: 0.6523 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4469 - accuracy: 0.8430 - val_loss: 1.1828 - val_accuracy: 0.6461 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4537 - accuracy: 0.8394 - val_loss: 1.2016 - val_accuracy: 0.6461 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4246 - accuracy: 0.8523 - val_loss: 1.2242 - val_accuracy: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4469 - accuracy: 0.8430 - val_loss: 1.2109 - val_accuracy: 0.6543 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4403 - accuracy: 0.8610 - val_loss: 1.2104 - val_accuracy: 0.6502 - lr: 1.0000e-05\n",
            "Epoch 1/200\n",
            "31/31 [==============================] - 2s 28ms/step - loss: 2.0427 - accuracy: 0.3567 - val_loss: 2.1582 - val_accuracy: 0.3930 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.8074 - accuracy: 0.4195 - val_loss: 2.0871 - val_accuracy: 0.4053 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.6089 - accuracy: 0.4720 - val_loss: 1.9391 - val_accuracy: 0.3663 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.4815 - accuracy: 0.4905 - val_loss: 1.8885 - val_accuracy: 0.3951 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.3667 - accuracy: 0.5368 - val_loss: 1.8430 - val_accuracy: 0.3930 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.4055 - accuracy: 0.5322 - val_loss: 1.8073 - val_accuracy: 0.3868 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.2365 - accuracy: 0.5775 - val_loss: 1.7000 - val_accuracy: 0.4259 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.1235 - accuracy: 0.6130 - val_loss: 1.7482 - val_accuracy: 0.4239 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 1.1458 - accuracy: 0.6042 - val_loss: 1.5813 - val_accuracy: 0.4918 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 1.1259 - accuracy: 0.6212 - val_loss: 1.4805 - val_accuracy: 0.4877 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.1029 - accuracy: 0.6109 - val_loss: 1.4889 - val_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.0590 - accuracy: 0.6557 - val_loss: 1.3804 - val_accuracy: 0.5103 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.9918 - accuracy: 0.6619 - val_loss: 1.4305 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9712 - accuracy: 0.6644 - val_loss: 1.2610 - val_accuracy: 0.5658 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9436 - accuracy: 0.6624 - val_loss: 1.1713 - val_accuracy: 0.6029 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9736 - accuracy: 0.6655 - val_loss: 1.5504 - val_accuracy: 0.5206 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9227 - accuracy: 0.6742 - val_loss: 1.3470 - val_accuracy: 0.5720 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8591 - accuracy: 0.7072 - val_loss: 1.1536 - val_accuracy: 0.6049 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8749 - accuracy: 0.6938 - val_loss: 1.0850 - val_accuracy: 0.6173 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8241 - accuracy: 0.7102 - val_loss: 1.3816 - val_accuracy: 0.5905 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8215 - accuracy: 0.7169 - val_loss: 1.4445 - val_accuracy: 0.5947 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8956 - accuracy: 0.6881 - val_loss: 1.5600 - val_accuracy: 0.5782 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8866 - accuracy: 0.6902 - val_loss: 1.1908 - val_accuracy: 0.6317 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.8490 - accuracy: 0.7195 - val_loss: 1.3991 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8266 - accuracy: 0.7195 - val_loss: 1.1989 - val_accuracy: 0.6152 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8299 - accuracy: 0.7205 - val_loss: 1.2481 - val_accuracy: 0.6214 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.7944 - accuracy: 0.7164 - val_loss: 1.1418 - val_accuracy: 0.6337 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7891 - accuracy: 0.7262 - val_loss: 1.1754 - val_accuracy: 0.6152 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7477 - accuracy: 0.7401 - val_loss: 1.1693 - val_accuracy: 0.6379 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7440 - accuracy: 0.7360 - val_loss: 1.4391 - val_accuracy: 0.6132 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.7834 - accuracy: 0.7324 - val_loss: 1.4428 - val_accuracy: 0.6235 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7800 - accuracy: 0.7262 - val_loss: 1.4122 - val_accuracy: 0.6111 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.7293 - val_loss: 1.3549 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6794 - accuracy: 0.7617 - val_loss: 1.8609 - val_accuracy: 0.3807 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.6372 - accuracy: 0.7746 - val_loss: 1.1988 - val_accuracy: 0.6420 - lr: 5.0000e-04\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5766 - accuracy: 0.7952 - val_loss: 1.2291 - val_accuracy: 0.6461 - lr: 5.0000e-04\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5581 - accuracy: 0.8096 - val_loss: 1.1082 - val_accuracy: 0.6523 - lr: 5.0000e-04\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5524 - accuracy: 0.8044 - val_loss: 1.1360 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5369 - accuracy: 0.8127 - val_loss: 1.3873 - val_accuracy: 0.6235 - lr: 5.0000e-04\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.5067 - accuracy: 0.8199 - val_loss: 1.1716 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.5055 - accuracy: 0.8281 - val_loss: 1.2397 - val_accuracy: 0.6564 - lr: 5.0000e-04\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.8353 - val_loss: 1.2865 - val_accuracy: 0.6481 - lr: 5.0000e-04\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4942 - accuracy: 0.8245 - val_loss: 1.3581 - val_accuracy: 0.5885 - lr: 5.0000e-04\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.4755 - accuracy: 0.8291 - val_loss: 1.2321 - val_accuracy: 0.6358 - lr: 2.5000e-04\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4288 - accuracy: 0.8554 - val_loss: 1.1781 - val_accuracy: 0.6379 - lr: 2.5000e-04\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4233 - accuracy: 0.8559 - val_loss: 1.1962 - val_accuracy: 0.6564 - lr: 2.5000e-04\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4353 - accuracy: 0.8492 - val_loss: 1.2470 - val_accuracy: 0.6379 - lr: 2.5000e-04\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4212 - accuracy: 0.8564 - val_loss: 1.2237 - val_accuracy: 0.6276 - lr: 2.5000e-04\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3992 - accuracy: 0.8580 - val_loss: 1.1884 - val_accuracy: 0.6420 - lr: 1.2500e-04\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3737 - accuracy: 0.8672 - val_loss: 1.1923 - val_accuracy: 0.6605 - lr: 1.2500e-04\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3921 - accuracy: 0.8631 - val_loss: 1.2448 - val_accuracy: 0.6420 - lr: 1.2500e-04\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.4065 - accuracy: 0.8616 - val_loss: 1.2564 - val_accuracy: 0.6337 - lr: 1.2500e-04\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8724 - val_loss: 1.2799 - val_accuracy: 0.6214 - lr: 1.2500e-04\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.8693 - val_loss: 1.2651 - val_accuracy: 0.6214 - lr: 1.2500e-04\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3766 - accuracy: 0.8791 - val_loss: 1.2890 - val_accuracy: 0.6358 - lr: 1.2500e-04\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3666 - accuracy: 0.8724 - val_loss: 1.2777 - val_accuracy: 0.6276 - lr: 6.2500e-05\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3537 - accuracy: 0.8796 - val_loss: 1.2617 - val_accuracy: 0.6399 - lr: 6.2500e-05\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3457 - accuracy: 0.8863 - val_loss: 1.2907 - val_accuracy: 0.6296 - lr: 6.2500e-05\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3606 - accuracy: 0.8780 - val_loss: 1.3011 - val_accuracy: 0.6337 - lr: 6.2500e-05\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.8739 - val_loss: 1.3015 - val_accuracy: 0.6255 - lr: 6.2500e-05\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3400 - accuracy: 0.8827 - val_loss: 1.2880 - val_accuracy: 0.6317 - lr: 3.1250e-05\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3369 - accuracy: 0.8832 - val_loss: 1.2664 - val_accuracy: 0.6358 - lr: 3.1250e-05\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3517 - accuracy: 0.8739 - val_loss: 1.2849 - val_accuracy: 0.6358 - lr: 3.1250e-05\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3447 - accuracy: 0.8837 - val_loss: 1.2975 - val_accuracy: 0.6317 - lr: 3.1250e-05\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 0.8801 - val_loss: 1.2658 - val_accuracy: 0.6440 - lr: 3.1250e-05\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3386 - accuracy: 0.8827 - val_loss: 1.2752 - val_accuracy: 0.6461 - lr: 1.5625e-05\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3215 - accuracy: 0.8960 - val_loss: 1.2716 - val_accuracy: 0.6276 - lr: 1.5625e-05\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3363 - accuracy: 0.8852 - val_loss: 1.2617 - val_accuracy: 0.6420 - lr: 1.5625e-05\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3309 - accuracy: 0.8919 - val_loss: 1.2640 - val_accuracy: 0.6399 - lr: 1.5625e-05\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3228 - accuracy: 0.8924 - val_loss: 1.2791 - val_accuracy: 0.6399 - lr: 1.5625e-05\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3415 - accuracy: 0.8904 - val_loss: 1.2946 - val_accuracy: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3346 - accuracy: 0.8914 - val_loss: 1.3053 - val_accuracy: 0.6399 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.8878 - val_loss: 1.3109 - val_accuracy: 0.6358 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3391 - accuracy: 0.8914 - val_loss: 1.3099 - val_accuracy: 0.6358 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3199 - accuracy: 0.8950 - val_loss: 1.3248 - val_accuracy: 0.6317 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3298 - accuracy: 0.8899 - val_loss: 1.2966 - val_accuracy: 0.6420 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3404 - accuracy: 0.8811 - val_loss: 1.2996 - val_accuracy: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.3387 - accuracy: 0.8883 - val_loss: 1.3068 - val_accuracy: 0.6317 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3444 - accuracy: 0.8837 - val_loss: 1.2954 - val_accuracy: 0.6337 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3559 - accuracy: 0.8780 - val_loss: 1.3109 - val_accuracy: 0.6337 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.8878 - val_loss: 1.3054 - val_accuracy: 0.6399 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3292 - accuracy: 0.8842 - val_loss: 1.3238 - val_accuracy: 0.6358 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3402 - accuracy: 0.8806 - val_loss: 1.3242 - val_accuracy: 0.6358 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 0.8775 - val_loss: 1.3210 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3400 - accuracy: 0.8765 - val_loss: 1.3460 - val_accuracy: 0.6235 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3489 - accuracy: 0.8857 - val_loss: 1.3324 - val_accuracy: 0.6255 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3478 - accuracy: 0.8760 - val_loss: 1.3415 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3118 - accuracy: 0.8950 - val_loss: 1.3372 - val_accuracy: 0.6276 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.3284 - accuracy: 0.8929 - val_loss: 1.3513 - val_accuracy: 0.6317 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3175 - accuracy: 0.8945 - val_loss: 1.3428 - val_accuracy: 0.6337 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3192 - accuracy: 0.8971 - val_loss: 1.3480 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3286 - accuracy: 0.8899 - val_loss: 1.3673 - val_accuracy: 0.6255 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3394 - accuracy: 0.8806 - val_loss: 1.3511 - val_accuracy: 0.6255 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3250 - accuracy: 0.8924 - val_loss: 1.3379 - val_accuracy: 0.6276 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3289 - accuracy: 0.8981 - val_loss: 1.3181 - val_accuracy: 0.6358 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3295 - accuracy: 0.8899 - val_loss: 1.3309 - val_accuracy: 0.6235 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3412 - accuracy: 0.8832 - val_loss: 1.3354 - val_accuracy: 0.6255 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.8945 - val_loss: 1.3192 - val_accuracy: 0.6276 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.3309 - accuracy: 0.8827 - val_loss: 1.3208 - val_accuracy: 0.6235 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.3391 - accuracy: 0.8868 - val_loss: 1.3215 - val_accuracy: 0.6296 - lr: 1.0000e-05\n"
          ]
        }
      ]
    }
  ]
}